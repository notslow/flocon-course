{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model to Detect Randomly Generated Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Needed Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Helper Functions for feature creations\n",
    "def get_tld(domain):\n",
    "    parts = domain.split(\".\")\n",
    "    lastIndex = len(parts)-1\n",
    "    tld = parts[lastIndex]\n",
    "    secondLD = parts[lastIndex-1]\n",
    "    if len(parts[lastIndex]) < 3 and len(secondLD) < 4:\n",
    "        tld = parts[lastIndex-1] + \".\" + tld\n",
    "    return(tld)\n",
    "\n",
    "\n",
    "def get_2ld(domain):\n",
    "    parts = domain.split(\".\")\n",
    "    num_parts = len(parts)\n",
    "    lastIndex = len(parts)-1\n",
    "    tld = parts[lastIndex]\n",
    "    secondLD = parts[lastIndex-1]\n",
    "    secondIndex = lastIndex-1\n",
    "    if len(parts[lastIndex]) < 3 and len(secondLD) < 4 and num_parts > 2:\n",
    "        secondIndex = lastIndex - 2\n",
    "    # print(domain + \" \" + str(secondIndex))\n",
    "    return(parts[secondIndex])\n",
    "\n",
    "\n",
    "def get_3ld(domain):\n",
    "    parts = domain.split(\".\")\n",
    "    if len(parts) < 3:\n",
    "        return \"\"\n",
    "    num_parts = len(parts)\n",
    "    lastIndex = len(parts)-1\n",
    "    tld = parts[lastIndex]\n",
    "    secondLD = parts[lastIndex-1]\n",
    "    secondIndex = lastIndex-1\n",
    "    if len(tld) < 3 and len(secondLD) < 4 and num_parts > 2:\n",
    "        secondIndex = lastIndex - 2\n",
    "    return(parts[secondIndex-1])\n",
    "\n",
    "\n",
    "def num_parts(domain):\n",
    "    return(len(domain.split(\".\")))\n",
    "\n",
    "\n",
    "def distinct_char(domain):\n",
    "    return(len(set(domain)))\n",
    "\n",
    "\n",
    "def count_digits(domain):\n",
    "    return(sum(c.isdigit() for c in domain))\n",
    "\n",
    "\n",
    "def count_dashes(domain):\n",
    "    return(sum(c == \"-\" for c in domain))\n",
    "\n",
    "\n",
    "def shannonEntropy(domain):\n",
    "    str_len = len(domain)\n",
    "    unique_chars = set(domain)\n",
    "    entropy = 0\n",
    "\n",
    "    for u in unique_chars:\n",
    "        count = domain.count(u)\n",
    "        fraction = count * 1.0 / str_len\n",
    "        entContrib = (fraction * np.log2(fraction))\n",
    "        entropy = entropy + entContrib\n",
    "    return(entropy * -1)\n",
    "\n",
    "\n",
    "def metricEntropy(domain):\n",
    "    strLength = len(domain)\n",
    "    return(shannonEntropy(domain)/strLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "datafile = \"data/training-data-raw.txt\"\n",
    "df = pd.read_csv(datafile, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Some data exploration here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Features\n",
    "# Create the following 23 features\n",
    "# \n",
    "# 1 Number of Domain Parts\n",
    "# 2 Length of tld\n",
    "# 3 Length of 2LD\n",
    "# 4 Length of 3LD\n",
    "# 5 Has a 3LD\n",
    "# 6 Has more than 3LD\n",
    "# 7 Len tld < 3 (ends in just a country code)\n",
    "# 8 Is .edu\n",
    "# 9 Is .gov\n",
    "# 10 Is .com\n",
    "# 11 Is .net\n",
    "# 12 Is .org\n",
    "# 13 Is .info\n",
    "# 14 Is .biz\n",
    "# 15 Distinct Char\n",
    "# 16 DigitCount\n",
    "# 17 Has Digit\n",
    "# 18 Num Dashes\n",
    "# 19 Has Dash\n",
    "# 20 Length of anything past 3LD\n",
    "# 21 Percent Distinct\n",
    "# 22 Percent Digits\n",
    "# 23 Metric Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_parts'] = df['domain'].apply(lambda x: num_parts(x))\n",
    "df['len_tld'] = df['domain'].apply(lambda x: len(get_tld(x)))\n",
    "df['len_2ld'] = df['domain'].apply(lambda x: len(get_2ld(x)))\n",
    "df['len_3ld'] = df['domain'].apply(lambda x: len(get_3ld(x)))\n",
    "df = df.assign(has_3ld=(df.len_3ld > 0)*1)\n",
    "df = df.assign(more_than_3ld=(df.num_parts > 3)*1)\n",
    "df = df.assign(two_letter_tld=(df.len_tld < 3)*1)\n",
    "df = df.assign(is_edu=(df.domain.str.contains(\".edu\")*1))\n",
    "df = df.assign(is_gov=(df.domain.str.contains(\".gov\") | df.domain.str.contains(\n",
    "    \".govt\") | df.domain.str.contains(\".gouv\"))*1)\n",
    "df = df.assign(is_com=(df.domain.str.contains(\".com\")*1))\n",
    "df = df.assign(is_net=(df.domain.str.contains(\".net\")*1))\n",
    "df = df.assign(is_org=(df.domain.str.contains(\".org\")*1))\n",
    "df = df.assign(is_info=(df.domain.str.contains(\".info\")*1))\n",
    "df = df.assign(is_biz=(df.domain.str.contains(\".biz\")*1))\n",
    "df['distinct_char'] = df['domain'].apply(lambda x: distinct_char(x))\n",
    "df['digit_count'] = df['domain'].apply(lambda x: count_digits(x))\n",
    "df = df.assign(has_digit=(df.digit_count > 0)*1)\n",
    "df = df.assign(num_dashes=(df.domain.str.count('-')))\n",
    "df = df.assign(has_dash=(df.domain.str.contains(\"-\")*1))\n",
    "df['length_extra'] = np.where(df['more_than_3ld'] == 1, df.domain.str.len(\n",
    ") - df.len_tld - df.len_2ld - df.len_3ld - 3, 0)\n",
    "df = df.assign(percent_distinct=df.distinct_char / df.domain.str.len())\n",
    "df = df.assign(percent_digits=df.digit_count / df.domain.str.len())\n",
    "df['entropy'] = df['domain'].apply(lambda x: metricEntropy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns for input\n",
    "columnList = ['num_parts', 'len_tld', 'len_2ld', 'len_3ld', 'has_3ld', 'more_than_3ld',\n",
    "              'two_letter_tld', 'is_edu', 'is_gov', 'is_com', 'is_net', 'is_org', 'is_info',\n",
    "              'is_biz', 'distinct_char', 'digit_count', 'has_digit', 'num_dashes', 'has_dash',\n",
    "              'length_extra', 'percent_distinct', 'percent_digits', 'entropy', 'ttl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineCount = df.groupby('label').count()[\"source\"]\n",
    "print(baselineCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineCount[1]/baselineCount[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineCount[1]*1.0/baselineCount[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = linear_model.LogisticRegressionCV(Cs=20, penalty='l2')\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=5, min_samples_leaf=1, max_depth=20) ## Notice the use of hyperparameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "acc = cross_val_score(\n",
    "    model, df[columnList], df.label, cv=10, scoring='accuracy')\n",
    "# scores = cross_val_score(model, df[columnList], df.label, cv=10, scoring='roc_auc')\n",
    "print(\"Acc:\" + str(acc))\n",
    "print(\"Overall:\" + str(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = cross_val_score(model, df[columnList], df.label, cv=10, scoring='roc_auc')\n",
    "print(\"AUC:\" + str(auc))\n",
    "print(\"Overall:\" + str(np.mean(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
